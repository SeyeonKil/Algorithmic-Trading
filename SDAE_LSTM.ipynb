{"cells":[{"cell_type":"markdown","id":"a8191b1a","metadata":{"id":"a8191b1a"},"source":["# Added:\n","\n","- LSTM layer and linear layer\n","\n","\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"WiAzyom19zRY"},"id":"WiAzyom19zRY","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"8c8aca73","metadata":{"id":"8c8aca73"},"source":["# Install packages"]},{"cell_type":"code","execution_count":null,"id":"e91d7670","metadata":{"id":"e91d7670"},"outputs":[],"source":["pip install gym\n","pip install yfinance\n","pip install numpy --upgrade #check if numpy is the most recent version"]},{"cell_type":"markdown","source":["# Google drive mount"],"metadata":{"id":"XIKjZqMfLJzd"},"id":"XIKjZqMfLJzd"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EeE1znX7ULDR","executionInfo":{"status":"ok","timestamp":1688015640628,"user_tz":-540,"elapsed":18843,"user":{"displayName":"Seyeon Kil","userId":"04202558955630011595"}},"outputId":"c9144336-b311-4de4-ef14-74ad8b6b708c"},"id":"EeE1znX7ULDR","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["pathSP = \"/content/drive/MyDrive/Colab Notebooks/Thesis code/data/SP2014-2016.csv\""],"metadata":{"id":"SrFG3WNwUPrE","executionInfo":{"status":"ok","timestamp":1688015640629,"user_tz":-540,"elapsed":5,"user":{"displayName":"Seyeon Kil","userId":"04202558955630011595"}}},"id":"SrFG3WNwUPrE","execution_count":2,"outputs":[]},{"cell_type":"code","source":["pathMSFT = \"/content/drive/MyDrive/Colab Notebooks/Thesis code/data/MSFT2014-2016.csv\""],"metadata":{"id":"NMVbH6qKUP2P","executionInfo":{"status":"ok","timestamp":1688015640629,"user_tz":-540,"elapsed":4,"user":{"displayName":"Seyeon Kil","userId":"04202558955630011595"}}},"id":"NMVbH6qKUP2P","execution_count":3,"outputs":[]},{"cell_type":"code","source":["pathcorrSP = \"/content/drive/MyDrive/Colab Notebooks/Thesis code/data/correlation_test_SP.csv\""],"metadata":{"id":"v3mFzv-Liv1U"},"id":"v3mFzv-Liv1U","execution_count":null,"outputs":[]},{"cell_type":"code","source":["pathcorrMSFT = \"/content/drive/MyDrive/Colab Notebooks/Thesis code/data/correlation_test_MSFT.csv\""],"metadata":{"id":"mQqS7K2njI8I"},"id":"mQqS7K2njI8I","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"b732fd00","metadata":{"id":"b732fd00"},"source":["# Trading_env"]},{"cell_type":"code","execution_count":4,"id":"9f471b97","metadata":{"id":"9f471b97","executionInfo":{"status":"ok","timestamp":1688015641174,"user_tz":-540,"elapsed":548,"user":{"displayName":"Seyeon Kil","userId":"04202558955630011595"}}},"outputs":[],"source":["import random\n","from statistics import mean\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","class TradingSystem_v0:\n","    def __init__(self, returns_data, k_value, action_dim, initial_balance,mode,stock):\n","        self.mode = mode  # test or train\n","        self.initial_balance = initial_balance\n","        self.balance = self.initial_balance\n","        self.k = k_value\n","        self.tickers = stock\n","        self.curr_position = 0\n","        self.action_space_dim = action_dim\n","        self.total_steps = returns_data.shape[0] - self.k\n","        self.current_step = 0\n","        self.reward = 0.0\n","        self.core = float(returns_data.iloc[returns_data.shape[0]-1,3])\n","        self.dev = float(np.std(returns_data.iloc[:,3]))\n","        self.trans_cost = 0.0005\n","        self.slippage_rate = 0.001\n","        for i in range(0,returns_data.shape[1]):\n","            col = np.asarray(returns_data.iloc[:,i])\n","            norm_value = preprocessing.normalize([col]).squeeze()\n","            for j in range(0,returns_data.shape[0]):\n","                returns_data.iloc[j,i] = norm_value[j]\n","        returns_data = returns_data.assign(MA = MA(returns_data.iloc[:,3],10), MACD = MACD(returns_data.iloc[:,3],10,20)\n","        ,ROC = ROC(returns_data.iloc[:,3],10), SR = SR(returns_data.iloc[:,3],10))\n","        self.initial_state = returns_data.iloc[0,:]\n","        self.state = self.initial_state\n","        self.batch = 20\n","        self.r_ts = returns_data\n","        self.is_terminal = False\n","\n","    # write step function that returns obs(next state), reward, is_done\n","    def step(self, action):\n","        self.current_step += 1\n","        if self.current_step == self.total_steps:\n","            self.is_terminal = True\n","\n","\n","        self.pos_change = action - self.action_space_dim//2  # get action(position) of the actor\n","\n","        self.curr_position = self.curr_position + self.pos_change\n","\n","        if self.pos_change == 0:\n","\n","            close_price = self.r_ts.iloc[self.current_step,3]\n","            close_price_bf = self.r_ts.iloc[self.current_step-1,3]\n","            self.reward = self.pos_change * (close_price - close_price_bf)\n","\n","\n","        else:\n","            close_price = self.r_ts.iloc[self.current_step,3]\n","            close_price_bf = self.r_ts.iloc[self.current_step-1,3]\n","            self.reward = self.pos_change * (close_price - close_price_bf)  - abs(self.pos_change)* (self.trans_cost+self.slippage_rate)\n","\n","\n","        self.state = self.r_ts.iloc[self.current_step+1,:]\n","\n","        return self.state, self.reward, self.is_terminal\n","\n","    def reset(self):\n","        self.r_ts = self.r_ts\n","        self.total_steps = len(self.r_ts) - self.k\n","        self.balance = self.initial_balance\n","        self.current_step = 0\n","        self.initial_state = self.r_ts.iloc[0,:]\n","        self.state = self.initial_state\n","        self.reward = 0.0\n","        self.is_terminal = False\n","        return self.state\n","\n"]},{"cell_type":"markdown","id":"c501005e","metadata":{"id":"c501005e"},"source":["# SDAE"]},{"cell_type":"code","execution_count":5,"id":"5d0a85e1","metadata":{"id":"5d0a85e1","executionInfo":{"status":"ok","timestamp":1688015650302,"user_tz":-540,"elapsed":9676,"user":{"displayName":"Seyeon Kil","userId":"04202558955630011595"}}},"outputs":[],"source":["import os\n","import sys\n","import json\n","import argparse\n","from collections import defaultdict\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import torch\n","from torch import nn\n","from torch.functional import F\n","from datetime import tzinfo, timedelta, datetime\n","\n","class SDAE(nn.Module):\n","    def __init__(self, input_dim):\n","        super(SDAE, self).__init__()\n","        self.num_layers = 4\n","\n","        # Encoder layers\n","        self.enc_fc_1 = nn.Linear(input_dim, 10)\n","        self.enc_fc_2 = nn.Linear(10, 16)\n","        self.encoder_object = nn.Sequential(*[self.enc_fc_1, nn.ReLU(), self.enc_fc_2])\n","\n","        # Decoder layers\n","        self.dec_fc_1 = nn.Linear(16, 10)\n","        self.dec_fc_2 = nn.Linear(10, input_dim)\n","        self.decoder_object = nn.Sequential(*[self.dec_fc_1, nn.ReLU(), self.dec_fc_2])\n","\n","    def forward(self, input, training=True):\n","        if training:\n","            encoded_output = self.encoder_object(input)\n","            decoded_output = self.decoder_object(encoded_output)\n","            return decoded_output\n","        else:\n","            with torch.no_grad():\n","                encoded_output = self.encoder_object(input)\n","                return encoded_output\n","\n","    def freeze_all_but(self, layer_index):\n","        if layer_index >= self.num_layers:\n","            print(\"Layer index error\")\n","            exit()\n","        layer_count = 0\n","        for name, param in self.encoder_object.named_parameters():\n","            if layer_index != layer_count:\n","                param.requires_grad = False\n","            if 'bias' in name:\n","                layer_count += 1\n","        layer_count = self.num_layers - 1\n","        for name, param in self.decoder_object.named_parameters():\n","            if layer_index != layer_count:\n","                param.requires_grad = False\n","            if 'bias' in name:\n","                layer_count -= 1\n","\n","    def unfreeze_all(self):\n","        for name, param in self.encoder_object.named_parameters():\n","            param.requires_grad = True\n","        for name, param in self.decoder_object.named_parameters():\n","            param.requires_grad = True"]},{"cell_type":"markdown","id":"6175267b","metadata":{"id":"6175267b"},"source":["# dqn"]},{"cell_type":"code","execution_count":6,"id":"d796d28d","metadata":{"id":"d796d28d","executionInfo":{"status":"ok","timestamp":1688015650303,"user_tz":-540,"elapsed":3,"user":{"displayName":"Seyeon Kil","userId":"04202558955630011595"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import random\n","import math\n","import numpy as np\n","\n","\n","class MLP(nn.Module):\n","    def __init__(self, state_dim, action_dim, hidden_dim=128):\n","        super(MLP, self).__init__()\n","        self.fc1 = nn.Linear(state_dim, 64)  # input layer\n","        self.fc2 = nn.Linear(64, hidden_dim)  # hidden layer 1\n","        self.fc3 = nn.Linear(hidden_dim, 128)  # hidden layer 2\n","        self.lstm_cells = nn.LSTMCell(128, 128) # lstm layer (returns hidden state and cell state)\n","        self.fc4 = nn.Linear(128, action_dim) # connects lstm layer to linear layer\n","\n","    def forward(self, x):\n","        # activation function\n","        x = torch.nn.functional.relu(self.fc1(x))\n","        x = torch.nn.functional.relu(self.fc2(x))\n","        x = torch.nn.functional.relu(self.fc3(x))\n","        hx,cx = self.lstm_cells(x)\n","        # x = hx.clone().detach()\n","        # x = torch.tensor(hx) (gives warning)\n","\n","\n","        return self.fc4(hx)\n","\n","\n","class ReplayBuffer:\n","    def __init__(self, capacity):\n","        self.capacity = capacity  # capacity of buffer\n","        self.buffer = []  # replay buffer\n","        self.position = 0\n","\n","    def push(self, state, action, reward, next_state, done):\n","        ''' replay buffer is a queue (LIFO)\n","        '''\n","        if len(self.buffer) < self.capacity:\n","            self.buffer.append(None)\n","        self.buffer[self.position] = (state, action, reward, next_state, done)\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        batch = random.sample(self.buffer, batch_size)\n","        state, action, reward, next_state, done = zip(*batch)\n","        return state, action, reward, next_state, done\n","\n","    def __len__(self):\n","        return len(self.buffer)\n","\n","\n","class DQN:\n","    def __init__(self, state_dim, action_dim, cfg):\n","\n","        self.action_dim = action_dim\n","        self.device = cfg.device  # cpu or gpu\n","        self.gamma = cfg.gamma  # discount factor\n","        self.frame_idx = 0  # attenuation\n","        self.epsilon = lambda frame_idx: cfg.epsilon_end + \\\n","                                         (cfg.epsilon_start - cfg.epsilon_end) * \\\n","                                         math.exp(-1. * frame_idx / cfg.epsilon_decay)\n","        self.batch_size = cfg.batch_size\n","        self.policy_net = MLP(state_dim, action_dim, hidden_dim=cfg.hidden_dim).to(self.device)\n","        self.target_net = MLP(state_dim, action_dim, hidden_dim=cfg.hidden_dim).to(self.device)\n","        for target_param, param in zip(self.target_net.parameters(),\n","                                       self.policy_net.parameters()):  # copy parameters to target net\n","            target_param.data.copy_(param.data)\n","        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=cfg.lr) # optimizer\n","        self.memory = ReplayBuffer(cfg.memory_capacity)  # experience replay\n","\n","    def choose_action(self, state):\n","        self.frame_idx += 1\n","        if random.random() > self.epsilon(self.frame_idx):\n","            with torch.no_grad():\n","                input_state = torch.tensor([state], device=self.device, dtype=torch.float32)   # received observation\n","                sdae = SDAE(input_state.shape[1])\n","                output_state = sdae.forward(input_state)     # denoised state (using SDAE)\n","                k = torch.stack((input_state.squeeze(),output_state.squeeze()))\n","                cor = torch.corrcoef(k)[0,1].item()\n","                q_values = self.policy_net(output_state)\n","                action = q_values.max(1)[1].item()  # choose the action with maximum q-value\n","\n","        else:\n","            input_state = torch.tensor([state], device=self.device, dtype=torch.float32)\n","            sdae = SDAE(input_state.shape[1])\n","            output_state = sdae.forward(input_state)\n","            action = random.randrange(self.action_dim) # pick random action\n","            k = torch.stack((input_state.squeeze(),output_state.squeeze()))\n","            cor = torch.corrcoef(k)[0,1].item()\n","        return action, cor\n","\n","    def update(self):\n","        if len(self.memory) < self.batch_size:\n","            return\n","        state_batch, action_batch, reward_batch, next_state_batch, done_batch = self.memory.sample(\n","            self.batch_size)\n","        # transfer to tensor\n","        state_batch = torch.tensor(state_batch, device=self.device, dtype=torch.float)\n","        action_batch = torch.tensor(action_batch, device=self.device).unsqueeze(1)\n","        reward_batch = torch.tensor(reward_batch, device=self.device, dtype=torch.float)\n","        next_state_batch = torch.tensor(next_state_batch, device=self.device, dtype=torch.float)\n","        done_batch = torch.tensor(np.float32(done_batch), device=self.device)\n","        q_values = self.policy_net(state_batch).gather(dim=1, index=action_batch)\n","        next_q_values = self.target_net(next_state_batch).max(1)[0].detach()\n","        # calculate the expected q-value, for final state, done_batch[0]=1 and the corresponding\n","        # expected_q_value equals to reward\n","        expected_q_values = reward_batch + self.gamma * next_q_values * (1 - done_batch)\n","        loss = nn.MSELoss()(q_values, expected_q_values.unsqueeze(1))\n","        # update the network\n","        self.optimizer.zero_grad()\n","        loss.backward()\n","        for param in self.policy_net.parameters():  # avoid gradient explosion by using clip\n","            param.grad.data.clamp_(-1, 1)\n","        self.optimizer.step()\n","\n","    def save(self, path):\n","        torch.save(self.target_net.state_dict(), path + 'dqn_checkpoint.pth')\n","\n","    def load(self, path):\n","        self.target_net.load_state_dict(torch.load(path + 'dqn_checkpoint.pth'))\n","        for target_param, param in zip(self.target_net.parameters(), self.policy_net.parameters()):\n","            param.data.copy_(target_param.data)"]},{"cell_type":"markdown","id":"5be83e66","metadata":{"id":"5be83e66"},"source":["# Main"]},{"cell_type":"code","execution_count":16,"id":"6aa75d54","metadata":{"id":"6aa75d54","executionInfo":{"status":"ok","timestamp":1688015759410,"user_tz":-540,"elapsed":410,"user":{"displayName":"Seyeon Kil","userId":"04202558955630011595"}}},"outputs":[],"source":["import sys\n","import os\n","import os.path\n","\n","\n","curr_path = os.path.abspath('')\n","\n","import gym\n","import torch\n","import numpy as np\n","import random\n","import yfinance as yf\n","import datetime as dt\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","curr_time = dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","random.seed(11)\n","\n","\n","\n","class Config:\n","    '''\n","    hyperparameters\n","    '''\n","\n","    def __init__(self):\n","        ################################## env hyperparameters ###################################\n","        self.algo_name = 'DQN' # algorithmic name\n","        self.env_name = 'TradingSystem_v0' # environment name\n","        self.device = torch.device(\n","            \"cuda\" if torch.cuda.is_available() else \"cpu\")  # examine GPU\n","        self.seed = 11 # random seed\n","        self.train_eps = 100 # number of training episode\n","        self.state_space_dim = 8 # state space size\n","        self.initial_balance = 1000000\n","        self.action_space_dim = 3 # action space size (only odd number can be applied)\n","        ################################################################################\n","\n","        ################################## algo hyperparameters ###################################\n","        self.gamma = 0.95  # discount factor\n","        self.epsilon_start = 0.90  # start epsilon of e-greedy policy\n","        self.epsilon_end = 0.01  # end epsilon of e-greedy policy\n","        self.epsilon_decay = 500  # attenuation rate of epsilon in e-greedy policy\n","        self.lr = 0.0001  # learning rate\n","        self.memory_capacity = 1000  # capacity of experience replay\n","        self.batch_size = 64  # size of mini-batch SGD\n","        self.target_update = 4  # update frequency of target network\n","        self.hidden_dim = 128  # dimension of hidden layer\n","        ################################################################################\n","\n","        ################################# save path ##############################\n","        self.result_path = curr_path + \"/outputs/\" + self.env_name + \\\n","                           '/' + curr_time + '/results/'\n","        self.model_path = curr_path + \"/outputs/\" + self.env_name + \\\n","                          '/' + curr_time + '/models/'\n","        self.save = True  # whether to save the image\n","        ################################################################################\n","\n","\n","def env_agent_config(data, cfg, mode,stock):\n","    ''' create environment and agent\n","    '''\n","    env = TradingSystem_v0(data, cfg.state_space_dim, cfg.action_space_dim, cfg.initial_balance, mode, stock)\n","    agent = DQN(cfg.state_space_dim, cfg.action_space_dim, cfg)\n","\n","    if cfg.seed != 0:  # set random seeds\n","        torch.manual_seed(cfg.seed)\n","        np.random.seed(cfg.seed)\n","    return env, agent\n","\n","\n","def train(cfg, env, agent):\n","    ''' training\n","    '''\n","    print('Start Training!')\n","    print(f'Environment：{cfg.env_name}, Algorithm：{cfg.algo_name}, Device：{cfg.device}, Stock: {env.tickers}')\n","    rewards = []  # record total rewards\n","    ma_rewards = []  # record moving average total rewards\n","    stocks = env.tickers\n","    ep_reward = 0\n","    state = env.reset()\n","    for i_ep in range(cfg.train_eps):\n","        ep_reward = 0\n","        state = env.reset()\n","        while True:\n","            action, cor = agent.choose_action(state)\n","            next_state, reward, done = env.step(action)\n","            agent.memory.push(state, action, reward, next_state, done)  # save transition\n","            state = next_state\n","            agent.update()\n","            ep_reward +=  reward\n","            if done:\n","                break\n","        if (i_ep + 1) % cfg.target_update == 0:  # update target network\n","            agent.target_net.load_state_dict(agent.policy_net.state_dict())\n","        sum_rewards = env.core * env.batch * (1+ep_reward) + env.dev * ep_reward\n","        rewards.append(sum_rewards)\n","        if ma_rewards:\n","            ma_rewards.append(0.9 * ma_rewards[-1] + 0.1 * sum_rewards)\n","        else:\n","            ma_rewards.append(sum_rewards)\n","        if (i_ep + 1) % 10 == 0:\n","            print('Episode：{}/{}, Reward：{}'.format(i_ep + 1, cfg.train_eps, sum_rewards))\n","    print('Finish Training!')\n","    return rewards, ma_rewards\n","\n","\n","def test(cfg, env, agent):\n","    print('Start Testing!')\n","    print(f'Environment：{cfg.env_name}, Algorithm：{cfg.algo_name}, Device：{cfg.device},Stock: {env.tickers}')\n","    ############# Test does not use e-greedy policy, so we set epsilon to 0 ###############\n","    cfg.epsilon_start = 0.0\n","    cfg.epsilon_end = 0.0\n","    ################################################################################\n","    stocks = env.tickers\n","    returns = []\n","    correlation = []\n","    ep_reward = 0\n","    state = env.reset()\n","    while True:\n","        action,cor = agent.choose_action(state)\n","        next_state, reward, done = env.step(action)\n","        state = next_state\n","        ep_reward += reward\n","        correlation.append(cor)\n","        if done:\n","            break\n","    sum_rewards = ep_reward * env.dev + env.core\n","    returns.append(sum_rewards)\n","    print(f\"Stock：{stocks}，Return：{sum_rewards:.1f}\")\n","    print('Finish Testing!')\n","    return stocks,sum_rewards,correlation\n"]},{"cell_type":"markdown","source":["# Indicators"],"metadata":{"id":"iGjQok1Nez-7"},"id":"iGjQok1Nez-7"},{"cell_type":"code","source":["def MA(sorted_data, period):\n","\tma_list = []\n","\tfor i in range(len(sorted_data)):\n","\t\tif(i < period - 1):\n","\t\t\tma_list.append(sorted_data[i])\n","\t\t\t#ma_list.append(None)\n","\t\telse:\n","\t\t\tma_sum = 0.0\n","\t\t\tfor j in range(i, i - period, -1):\n","\t\t\t\tma_sum += sorted_data[j]\n","\t\t\tcurr_ma = ma_sum / period\n","\t\t\tma_list.append(curr_ma)\n","\treturn ma_list\n","\n","def EMA(data, period):\n","    sorted_data = np.array([data[i] for i in sorted(data.keys())])\n","    sma = np.mean(sorted_data[:period])\n","    ema_list = []\n","    smooth_weighting = 2.0 / (period + 1)\n","    for i in range(len(sorted_data)):\n","        if i < period - 1:\n","            ema_list.append(sma)\n","        else:\n","            new_ema = (sorted_data[i] - ema_list[-1]) * smooth_weighting + ema_list[-1]\n","            ema_list.append(new_ema)\n","    assert len(ema_list) == len(sorted_data)\n","    return np.array(ema_list)\n","\n","def MACD(sorted_data, period_1, period_2):\n","\tperiod_1_ema_list = EMA(sorted_data, period_1)\n","\tperiod_2_ema_list = EMA(sorted_data, period_2)\n","\tassert len(period_1_ema_list) == len(period_2_ema_list)\n","\tmacd_list = period_1_ema_list - period_2_ema_list\n","\treturn macd_list\n","\n","\n","def ROC(data, period):\n","    roc_list = []\n","    for i in range(len(data)):\n","        if i == 0:\n","            roc_list.append(0.0)\n","        elif i < period:\n","            curr_roc = (data[i] - data[0]) / data[0]\n","            roc_list.append(curr_roc)\n","        else:\n","            curr_roc = (data[i] - data[i - period]) / data[i - period]\n","            roc_list.append(curr_roc)\n","    return roc_list\n","\n","def SR(sorted_data, period, risk_free_rate=0.007):\n","    # trading hours per day\n","    risk_free_rate = risk_free_rate / (6.5 * 60)\n","    sr_list = []\n","    for i in range(len(sorted_data)):\n","        if i < period:\n","            sr_list.append(0.0)\n","        else:\n","            expected_return_list = []\n","            for j in range(i, i - period, -1):\n","                perc_change = (sorted_data[j] - sorted_data[j - 1]) / sorted_data[j - 1]\n","                expected_return_list.append(perc_change)\n","            expected_return_list = np.array(expected_return_list)\n","            std = np.std(expected_return_list)\n","            if std != 0.0:\n","                sr_list.append((np.mean(expected_return_list) - risk_free_rate) / std)\n","            else:\n","                sr_list.append(0.0)\n","    return sr_list\n"],"metadata":{"id":"SmkEeZAccyMJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688015695591,"user_tz":-540,"elapsed":4,"user":{"displayName":"Seyeon Kil","userId":"04202558955630011595"}},"outputId":"8227c57a-d54b-4535-d317-96e76afb13b8"},"id":"SmkEeZAccyMJ","execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}]},{"cell_type":"markdown","source":["# Load Dataset"],"metadata":{"id":"XnVh1iyRPAbO"},"id":"XnVh1iyRPAbO"},{"cell_type":"code","source":["import pandas as pd\n","from sklearn import preprocessing\n","import math\n","\n","### S&P 500 ###\n","# SP = pd.read_csv(r'/Users/gilseyeon/Downloads/data/SPXUSD/SP2012.csv')\n","\n","SP = pd.read_csv(pathSP)\n","oo = range(0,len(SP),30)\n","returns_SP = SP.iloc[oo,].reset_index(drop=True)\n","\n","returns_SP = returns_SP.iloc[:,2:6] # remove time stamps\n","\n","#splitting train and test set\n","splitter = math.ceil(returns_SP.shape[0]*0.9)\n","SP_train = returns_SP.iloc[0:splitter,:]\n","SP_test = returns_SP.iloc[splitter+1:,:].reset_index(drop=True)\n","\n","\n","### Microsoft ###\n","MSFT = pd.read_csv(pathMSFT)\n","dd = range(0,len(MSFT),6)\n","returns_MSFT = MSFT.iloc[dd,].reset_index(drop=True)\n","returns_MSFT = returns_MSFT.iloc[:,1:5] # remove time stamps\n","\n","#splitting train and test set\n","splitter = math.ceil(returns_MSFT.shape[0]*0.9)\n","MSFT_train = returns_MSFT.iloc[0:splitter,:]\n","MSFT_test = returns_MSFT.iloc[splitter+1:,:].reset_index(drop=True)\n","\n"],"metadata":{"id":"CcxZTZszHCWg","executionInfo":{"status":"ok","timestamp":1688015695591,"user_tz":-540,"elapsed":3353,"user":{"displayName":"Seyeon Kil","userId":"04202558955630011595"}}},"id":"CcxZTZszHCWg","execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Train / Test"],"metadata":{"id":"5VpNFbdpvqkQ"},"id":"5VpNFbdpvqkQ"},{"cell_type":"code","execution_count":null,"id":"5bb8c342","metadata":{"id":"5bb8c342","outputId":"bb92f2a3-637e-4248-f6be-61c22d5bbf50","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687855488418,"user_tz":-540,"elapsed":15160619,"user":{"displayName":"Seyeon Kil","userId":"04202558955630011595"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Start Training!\n","Environment：TradingSystem_v0, Algorithm：DQN, Device：cpu, Stock: SP500\n","Episode：10/100, Reward：29756.582744172407\n","Episode：20/100, Reward：34149.27518358311\n","Episode：30/100, Reward：35411.574554890074\n","Episode：40/100, Reward：35407.284238092245\n","Episode：50/100, Reward：33821.865815207275\n","Episode：60/100, Reward：34265.25656620571\n","Episode：70/100, Reward：35094.19199431144\n","Episode：80/100, Reward：36794.19383142421\n","Episode：90/100, Reward：36928.97547866655\n","Episode：100/100, Reward：36049.42484767726\n","Finish Training!\n"]}],"source":["#Training SP500\n","cfg = Config()\n","env, agent = env_agent_config(SP_train, cfg, 'train','SP500')\n","rewards_train_SP, ma_rewards_train_SP = train(cfg, env, agent)"]},{"cell_type":"code","source":["rewards_train_SP"],"metadata":{"id":"XdVRJOFAEeHs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687855488418,"user_tz":-540,"elapsed":9,"user":{"displayName":"Seyeon Kil","userId":"04202558955630011595"}},"outputId":"8ea21fd8-f157-489d-c7aa-4833f963de45"},"id":"XdVRJOFAEeHs","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"output_type":"execute_result","data":{"text/plain":["[-159919.26372262044,\n"," -111319.55145007331,\n"," -75752.94503514578,\n"," -39130.809659565944,\n"," -12324.762133000098,\n"," 3697.3731945779364,\n"," 20512.526767792802,\n"," 23908.818594901102,\n"," 25541.91256062946,\n"," 29756.582744172407,\n"," 29957.646481481424,\n"," 29961.21371117852,\n"," 28685.175684957117,\n"," 31267.934803321994,\n"," 32545.152907691834,\n"," 30851.225002225452,\n"," 31861.801083997663,\n"," 32431.14796314464,\n"," 34001.09232207336,\n"," 34149.27518358311,\n"," 33307.90265734432,\n"," 32488.415567355183,\n"," 32194.219999807552,\n"," 29868.755868064352,\n"," 35279.82987347092,\n"," 34142.04431257552,\n"," 35722.56888196255,\n"," 34715.39613014457,\n"," 35972.48927432607,\n"," 35411.574554890074,\n"," 35355.27106681388,\n"," 34848.442368345095,\n"," 33436.36934390671,\n"," 33755.05346126671,\n"," 34644.293459406166,\n"," 35791.9130048719,\n"," 33568.137164113075,\n"," 34081.06486124774,\n"," 34897.804220253995,\n"," 35407.284238092245,\n"," 35733.48846130014,\n"," 35645.995816277864,\n"," 36040.41036182114,\n"," 33385.175671342535,\n"," 35609.69773798934,\n"," 35858.146889131865,\n"," 36618.67917167536,\n"," 36039.15701084649,\n"," 34384.75697271867,\n"," 33821.865815207275,\n"," 35781.307727394094,\n"," 36109.584800290846,\n"," 34520.21350125505,\n"," 34517.031918011715,\n"," 34905.372531908615,\n"," 34904.33514294806,\n"," 34006.4663054062,\n"," 35091.540674941985,\n"," 35203.328152380185,\n"," 34265.25656620571,\n"," 36159.26095405955,\n"," 36111.12738610579,\n"," 36226.04824098062,\n"," 36281.91787679636,\n"," 36100.66672604815,\n"," 35661.51808604083,\n"," 35594.94676113385,\n"," 34708.7919346243,\n"," 36293.824711055524,\n"," 35094.19199431144,\n"," 37059.370397497616,\n"," 36099.943638947385,\n"," 36417.22978791259,\n"," 36296.186795584676,\n"," 35662.04834991472,\n"," 35477.519204309734,\n"," 35666.868930586454,\n"," 36490.887366407005,\n"," 35846.96314197345,\n"," 36794.19383142421,\n"," 35091.25144010168,\n"," 35972.585685939506,\n"," 36286.208193594204,\n"," 36104.86063123256,\n"," 36160.874884468445,\n"," 35398.774949090504,\n"," 36544.780564147346,\n"," 37110.708687481936,\n"," 36353.64722302209,\n"," 36928.97547866655,\n"," 35280.11910831123,\n"," 37311.3385725305,\n"," 34956.180558019034,\n"," 35735.3202819554,\n"," 37052.525172943766,\n"," 37498.47083169822,\n"," 36349.2122888041,\n"," 35468.07086619314,\n"," 36034.095401141174,\n"," 36049.42484767726]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["ma_rewards_train_SP"],"metadata":{"id":"-1AsBgHsJfav","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687855488419,"user_tz":-540,"elapsed":7,"user":{"displayName":"Seyeon Kil","userId":"04202558955630011595"}},"outputId":"12ea83b1-14d8-4b2e-aadf-156550d9eb27"},"id":"-1AsBgHsJfav","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[-159919.26372262044,\n"," -155059.29249536572,\n"," -147128.65774934372,\n"," -136328.87294036595,\n"," -123928.46185962936,\n"," -111165.87835420863,\n"," -97998.0378420085,\n"," -85807.35219831755,\n"," -74672.42572242285,\n"," -64229.52487576333,\n"," -54810.80774003886,\n"," -46333.60559491712,\n"," -38831.7274669297,\n"," -31821.761239904532,\n"," -25385.069825144896,\n"," -19761.440342407863,\n"," -14599.116199767312,\n"," -9896.089783476116,\n"," -5506.371572921169,\n"," -1540.806897270741,\n"," 1944.064058190765,\n"," 4998.499209107207,\n"," 7718.071288177242,\n"," 9933.139746165954,\n"," 12467.808758896452,\n"," 14635.23231426436,\n"," 16743.96597103418,\n"," 18541.10898694522,\n"," 20284.247015683304,\n"," 21796.979769603982,\n"," 23152.808899324973,\n"," 24322.372246226987,\n"," 25233.77195599496,\n"," 26085.900106522135,\n"," 26941.73944181054,\n"," 27826.756798116676,\n"," 28400.894834716317,\n"," 28968.91183736946,\n"," 29561.801075657913,\n"," 30146.34939190135,\n"," 30705.06329884123,\n"," 31199.156550584892,\n"," 31683.281931708516,\n"," 31853.47130567192,\n"," 32229.09394890366,\n"," 32591.999242926482,\n"," 32994.667235801375,\n"," 33299.11621330589,\n"," 33407.68028924717,\n"," 33449.09884184318,\n"," 33682.319730398274,\n"," 33925.046237387534,\n"," 33984.56296377428,\n"," 34037.80985919803,\n"," 34124.566126469086,\n"," 34202.54302811698,\n"," 34182.935355845904,\n"," 34273.795887755514,\n"," 34366.74911421798,\n"," 34356.599859416754,\n"," 34536.86596888104,\n"," 34694.292110603514,\n"," 34847.467723641224,\n"," 34990.912738956744,\n"," 35101.88813766588,\n"," 35157.851132503376,\n"," 35201.560695366425,\n"," 35152.28381929221,\n"," 35266.43790846854,\n"," 35249.21331705283,\n"," 35430.22902509731,\n"," 35497.20048648232,\n"," 35589.20341662534,\n"," 35659.90175452128,\n"," 35660.11641406062,\n"," 35641.85669308553,\n"," 35644.35791683562,\n"," 35729.01086179276,\n"," 35740.80608981083,\n"," 35846.14486397217,\n"," 35770.655521585126,\n"," 35790.84853802057,\n"," 35840.38450357793,\n"," 35866.832116343394,\n"," 35896.2363931559,\n"," 35846.49024874936,\n"," 35916.31928028916,\n"," 36035.75822100844,\n"," 36067.547121209805,\n"," 36153.68995695548,\n"," 36066.33287209106,\n"," 36190.833442135,\n"," 36067.3681537234,\n"," 36034.1633665466,\n"," 36135.999547186315,\n"," 36272.24667563751,\n"," 36279.94323695417,\n"," 36198.75599987806,\n"," 36182.289940004375,\n"," 36169.00343077166]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# Testing SP500\n","env, agent = env_agent_config(SP_test, cfg, 'test',\"SP500\")\n","stocks_test_SP, rewards_test_SP, correlation_test_SP = test(cfg, env, agent)"],"metadata":{"id":"nvLiHqgstzJn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687855490343,"user_tz":-540,"elapsed":1928,"user":{"displayName":"Seyeon Kil","userId":"04202558955630011595"}},"outputId":"b779ccba-1760-4337-d94f-0823aab8f022"},"id":"nvLiHqgstzJn","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Start Testing!\n","Environment：TradingSystem_v0, Algorithm：DQN, Device：cpu,Stock: SP500\n","Stock：SP500，Return：2137.4\n","Finish Testing!\n"]}]},{"cell_type":"code","source":["rewards_test_SP = 2137.386746022535"],"metadata":{"id":"g0QNTVa7oZ2u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687855490344,"user_tz":-540,"elapsed":6,"user":{"displayName":"Seyeon Kil","userId":"04202558955630011595"}},"outputId":"42c4afef-7271-4764-df8b-4eb7e6dfdcf2"},"id":"g0QNTVa7oZ2u","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"output_type":"execute_result","data":{"text/plain":["2137.386746022535"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["correlation_test_SP = pd.DataFrame(correlation_test_SP).to_csv('/content/drive/My Drive/correlation_test_SP.csv')"],"metadata":{"id":"syQxaUDw5eTo"},"id":"syQxaUDw5eTo","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training Microsoft\n","cfg = Config()\n","env, agent = env_agent_config(MSFT_train, cfg, 'train','MSFT')\n","rewards_train_MSFT, ma_rewards_train_MSFT = train(cfg, env, agent)"],"metadata":{"id":"mL1wsbHzu_FG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687874672902,"user_tz":-540,"elapsed":16658661,"user":{"displayName":"Seyeon Kil","userId":"04202558955630011595"}},"outputId":"c3fb3efb-a0b7-4b22-b04e-e8fd56b5ce36"},"id":"mL1wsbHzu_FG","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Start Training!\n","Environment：TradingSystem_v0, Algorithm：DQN, Device：cpu, Stock: MSFT\n","Episode：10/100, Reward：959.9293519126438\n","Episode：20/100, Reward：897.2879098321079\n","Episode：30/100, Reward：908.4821707613372\n","Episode：40/100, Reward：971.73837924582\n","Episode：50/100, Reward：943.3148046943527\n","Episode：60/100, Reward：961.7204148844937\n","Episode：70/100, Reward：976.7511805015234\n","Episode：80/100, Reward：967.8779757556414\n","Episode：90/100, Reward：981.9977606428424\n","Episode：100/100, Reward：1011.0210801639878\n","Finish Training!\n"]}]},{"cell_type":"code","source":["rewards_train_MSFT"],"metadata":{"id":"YXffygeP5x_d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687874672902,"user_tz":-540,"elapsed":4,"user":{"displayName":"Seyeon Kil","userId":"04202558955630011595"}},"outputId":"db0b83fc-0229-4eb1-e442-638d473c24ff"},"id":"YXffygeP5x_d","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[-4134.2044817276565,\n"," -2463.6940359760524,\n"," -960.3834196956681,\n"," 380.8042370256189,\n"," 805.9308171815887,\n"," 861.5548298088413,\n"," 834.4596308514432,\n"," 909.5001714142063,\n"," 926.9579832746917,\n"," 959.9293519126438,\n"," 850.9567736954604,\n"," 860.5269167252496,\n"," 841.8569132825774,\n"," 924.7233068447848,\n"," 882.6642404499964,\n"," 909.5985876906674,\n"," 894.1043837541355,\n"," 952.6672415912049,\n"," 878.5702940844576,\n"," 897.2879098321079,\n"," 875.0785789241758,\n"," 888.6836039890852,\n"," 881.7926760326435,\n"," 909.5896193009659,\n"," 971.7573244326775,\n"," 931.6002269740932,\n"," 944.2598996338111,\n"," 940.9693107218429,\n"," 961.0091014304912,\n"," 908.4821707613372,\n"," 930.8074873821712,\n"," 965.0394323044873,\n"," 950.589533436552,\n"," 955.6508669829365,\n"," 950.0669183095617,\n"," 950.8396613962165,\n"," 970.0393388180601,\n"," 945.745779890078,\n"," 952.8064018199221,\n"," 971.73837924582,\n"," 939.9491456655608,\n"," 898.2010120543936,\n"," 973.8046516308298,\n"," 932.062034677286,\n"," 957.9370794704101,\n"," 931.5474035878611,\n"," 943.1755183326093,\n"," 913.5023312459105,\n"," 902.676546691641,\n"," 943.3148046943527,\n"," 969.5750851904032,\n"," 966.0795535549215,\n"," 928.733276470392,\n"," 957.9057115619325,\n"," 980.1756086837258,\n"," 956.1626659492979,\n"," 980.7453588955029,\n"," 981.9669291213088,\n"," 982.2931811160473,\n"," 961.7204148844937,\n"," 976.8866932990223,\n"," 956.6040265821905,\n"," 969.3721378263213,\n"," 967.699466180722,\n"," 901.3010119574669,\n"," 983.747736374792,\n"," 967.1201013150704,\n"," 978.51628234529,\n"," 1009.091371894887,\n"," 976.7511805015234,\n"," 958.202934295269,\n"," 990.1212895404965,\n"," 985.0858527557618,\n"," 1012.7858601755881,\n"," 1003.7200925168572,\n"," 980.2977761740615,\n"," 1004.6966385868639,\n"," 964.8314429031329,\n"," 983.7620471784545,\n"," 967.8779757556414,\n"," 972.3488948653309,\n"," 995.0551560935403,\n"," 961.0105389475008,\n"," 998.9982275395079,\n"," 971.6971203620976,\n"," 986.5540751538363,\n"," 968.1322660779904,\n"," 1000.8139428552981,\n"," 987.2759232474164,\n"," 981.9977606428424,\n"," 966.7964668886182,\n"," 970.0444666772437,\n"," 991.9016676844245,\n"," 968.0990744539039,\n"," 978.1908242032285,\n"," 1010.7562122911056,\n"," 983.6707755760858,\n"," 982.2198892040371,\n"," 995.7348656288103,\n"," 1011.0210801639878]"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["ma_rewards_train_MSFT"],"metadata":{"id":"TcYSrRhN7wsh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687874672902,"user_tz":-540,"elapsed":3,"user":{"displayName":"Seyeon Kil","userId":"04202558955630011595"}},"outputId":"b98ccba6-684d-430b-e0d2-894756898db2"},"id":"TcYSrRhN7wsh","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[-4134.2044817276565,\n"," -3967.153437152496,\n"," -3666.476435406813,\n"," -3261.74836816357,\n"," -2854.980449629054,\n"," -2483.3269216852646,\n"," -2151.5482664315937,\n"," -1845.4434226470137,\n"," -1568.2032820548432,\n"," -1315.3900186580945,\n"," -1098.7553394227389,\n"," -902.8271138079401,\n"," -728.3587110988883,\n"," -563.050509304521,\n"," -418.4790343290693,\n"," -285.6712721270956,\n"," -167.6937065389725,\n"," -55.65761172595475,\n"," 37.76517885508649,\n"," 123.71745195278862,\n"," 198.85356464992734,\n"," 267.83656858384313,\n"," 329.2321793287232,\n"," 387.26792332594744,\n"," 445.71686343662043,\n"," 494.30519979036774,\n"," 539.3006697747121,\n"," 579.4675338694252,\n"," 617.6216906255318,\n"," 646.7077386391122,\n"," 675.1177135134182,\n"," 704.109885392525,\n"," 728.7578501969277,\n"," 751.4471518755286,\n"," 771.3091285189319,\n"," 789.2621818066604,\n"," 807.3398975078003,\n"," 821.1804857460281,\n"," 834.3430773534176,\n"," 848.0826075426579,\n"," 857.2692613549482,\n"," 861.3624364248928,\n"," 872.6066579454866,\n"," 878.5521956186666,\n"," 886.4906840038409,\n"," 890.9963559622429,\n"," 896.2142721992795,\n"," 897.9430781039428,\n"," 898.4164249627127,\n"," 902.9062629358767,\n"," 909.5731451613293,\n"," 915.2237860006885,\n"," 916.5747350476589,\n"," 920.7078326990863,\n"," 926.6546102975503,\n"," 929.6054158627252,\n"," 934.719410166003,\n"," 939.4441620615336,\n"," 943.7290639669849,\n"," 945.5281990587358,\n"," 948.6640484827645,\n"," 949.4580462927071,\n"," 951.4494554460686,\n"," 953.0744565195339,\n"," 947.8971120633273,\n"," 951.4821744944737,\n"," 953.0459671765334,\n"," 955.5929986934091,\n"," 960.9428360135569,\n"," 962.5236704623536,\n"," 962.0915968456452,\n"," 964.8945661151304,\n"," 966.9136947791935,\n"," 971.500911318833,\n"," 974.7228294386355,\n"," 975.280324112178,\n"," 978.2219555596467,\n"," 976.8829042939954,\n"," 977.5708185824412,\n"," 976.6015342997613,\n"," 976.1762703563182,\n"," 978.0641589300404,\n"," 976.3587969317865,\n"," 978.6227399925588,\n"," 977.9301780295127,\n"," 978.7925677419452,\n"," 977.7265375755497,\n"," 980.0352781035247,\n"," 980.7593426179138,\n"," 980.8831844204067,\n"," 979.4745126672278,\n"," 978.5315080682294,\n"," 979.8685240298489,\n"," 978.6915790722545,\n"," 978.6415035853519,\n"," 981.8529744559272,\n"," 982.0347545679431,\n"," 982.0532680315525,\n"," 983.4214277912783,\n"," 986.1813930285493]"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["rewards_train_MSFT = pd.DataFrame(rewards_train_MSFT).to_csv('/content/drive/My Drive/rewards_train_MSFT.csv')"],"metadata":{"id":"3KzVn0hp4594"},"id":"3KzVn0hp4594","execution_count":null,"outputs":[]},{"cell_type":"code","source":["ma_rewards_train_MSFT = pd.DataFrame(ma_rewards_train_MSFT).to_csv('/content/drive/My Drive/ma_rewards_train_MSFT.csv')"],"metadata":{"id":"e3ycRZTf46Ih"},"id":"e3ycRZTf46Ih","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","correlation_train_MSFT = pd.DataFrame(correlation_train_MSFT).to_csv('/content/drive/My Drive/correlation_train_MSFT.csv')"],"metadata":{"id":"xgwhAW1641L2"},"id":"xgwhAW1641L2","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Testing Microsoft\n","cfg = Config()\n","env, agent = env_agent_config(MSFT_test, cfg, 'test',\"MSFT\")\n","stocks_test_MSFT, rewards_test_MSFT, correlation_test_MSFT = test(cfg, env, agent)"],"metadata":{"id":"qXnHMSkQu_Jx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688015715250,"user_tz":-540,"elapsed":3696,"user":{"displayName":"Seyeon Kil","userId":"04202558955630011595"}},"outputId":"8e6dc402-cfc0-4c56-c1f9-998c7ed84a58"},"id":"qXnHMSkQu_Jx","execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]},{"output_type":"stream","name":"stdout","text":["Start Testing!\n","Environment：TradingSystem_v0, Algorithm：DQN, Device：cpu,Stock: MSFT\n","Stock：MSFT，Return：59.6\n","Finish Testing!\n"]}]},{"cell_type":"code","source":["rewards_test_MSFT"],"metadata":{"id":"GbQ7-YlfjpDa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688015739242,"user_tz":-540,"elapsed":373,"user":{"displayName":"Seyeon Kil","userId":"04202558955630011595"}},"outputId":"230a6c7a-b1ed-4666-9dd0-d847a10f0df3"},"id":"GbQ7-YlfjpDa","execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["59.6021745894492"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["save_correlation_test_MSFT = pd.DataFrame(correlation_test_MSFT).to_csv('/content/drive/My Drive/correlation_test_MSFT.csv')"],"metadata":{"id":"Lj6SHGnn40Pd"},"id":"Lj6SHGnn40Pd","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Save results"],"metadata":{"id":"xFD_BOFA4pPh"},"id":"xFD_BOFA4pPh"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[],"gpuType":"T4"}},"nbformat":4,"nbformat_minor":5}